{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN \n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 579 entries, 0 to 578\n",
      "Data columns (total 12 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Unnamed: 0                      579 non-null    int64  \n",
      " 1   Age_std                         579 non-null    float64\n",
      " 2   Total_Bilirubin_std             579 non-null    float64\n",
      " 3   Direct_Bilirubin_std            579 non-null    float64\n",
      " 4   Alkaline_Phosphotase_std        579 non-null    float64\n",
      " 5   Alamine_Aminotransferase_std    579 non-null    float64\n",
      " 6   Aspartate_Aminotransferase_std  579 non-null    float64\n",
      " 7   Total_Protiens_std              579 non-null    float64\n",
      " 8   Albumin_std                     579 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio_std  579 non-null    float64\n",
      " 10  Is_male_std                     579 non-null    int64  \n",
      " 11  Liver_disease                   579 non-null    int64  \n",
      "dtypes: float64(9), int64(3)\n",
      "memory usage: 54.4 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/indian_liver_patient_preprocessed.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Liver_disease\"]\n",
    "X = df.drop([\"Unnamed: 0\", \"Liver_disease\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare logistic regression, KNN and decision trees classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.759\n",
      "K Nearest Neighbours : 0.701\n",
      "Classification Tree : 0.730\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)   \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.770\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)    \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)  \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning for a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 1, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'max_depth': 2, 'min_samples_leaf': 0.12}\n",
      "Best CV accuracy 0.665\n",
      "Test set ROC AUC score: 0.707\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "print(dt.get_params())\n",
    "\n",
    "# Define params_dt\n",
    "params_dt = {\n",
    "    \"max_depth\": [2, 3, 4],\n",
    "    \"min_samples_leaf\": [0.12, 0.14, 0.16, 0.18]\n",
    "}\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring=\"roc_auc\",\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print(\"Best hyperparameters:\\n\", best_hyperparams)\n",
    "\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print(\"Best CV accuracy {:.3f}\".format(best_CV_score))\n",
    "\n",
    "# Extracting the best model\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=SEED)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(estimator=dt, n_estimators=180, random_state=SEED)\n",
    "\n",
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(estimator=dt, n_estimators=50, random_state=SEED)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Bag Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.707, OOB accuracy: 0.677\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=SEED)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=SEED)\n",
    "\n",
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
